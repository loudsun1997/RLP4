
This was run for the double dueling dqn 
python main.py --train_dqn --dqn_type "double dueling dqn" --learning_rate 0.0001 
--batch_size 64 --optimizer 'rmsprop' --target_update_freq 10000 
--decay_rate 70000 --log_dir "logs/$SLURM_JOB_ID"

Run with max_memory of 10e4
Added reward clipping to code
80000 episodes
final epsilon 0.1
waits for 40000 samples before starting trainings